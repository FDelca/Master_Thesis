{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T01:06:36.037864Z",
     "start_time": "2020-04-20T01:06:36.034855Z"
    }
   },
   "source": [
    "# 01-Data Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:09:49.083861Z",
     "start_time": "2020-06-04T16:09:46.672524Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "# Packages for this notebook\n",
    "import random\n",
    "from random import randint\n",
    "import math\n",
    "import datetime\n",
    "from statistics import mean    \n",
    "from numpy import array\n",
    "\n",
    "\n",
    "# Multiple imputation packages\n",
    "from impyute.imputation.cs import mice\n",
    "from missingpy import MissForest\n",
    "\n",
    "# Error metrics packages\n",
    "from tsmetrics import tsmetrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Imputation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:09:49.250109Z",
     "start_time": "2020-06-04T16:09:49.087462Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import dataset from 01-00-Data_Treatment notebook\n",
    "dt = pd.read_csv('Preprocessed_Data/_01_dt_00.csv',index_col=[0],parse_dates=[0], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:09:49.293911Z",
     "start_time": "2020-06-04T16:09:49.254097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>civil</th>\n",
       "      <th>south_tower</th>\n",
       "      <th>wt_temp</th>\n",
       "      <th>wt_tmpap</th>\n",
       "      <th>wt_hr</th>\n",
       "      <th>wt_max_windgust</th>\n",
       "      <th>wt_mean_windspd</th>\n",
       "      <th>wt_mean_pres</th>\n",
       "      <th>wt_mean_solarrad</th>\n",
       "      <th>wt_rain_day</th>\n",
       "      <th>t_hour</th>\n",
       "      <th>t_month</th>\n",
       "      <th>t_dayofweek</th>\n",
       "      <th>t_year</th>\n",
       "      <th>miss_civil</th>\n",
       "      <th>miss_south_tower</th>\n",
       "      <th>miss_wt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2014-01-01 01:00:00</td>\n",
       "      <td>65.99413</td>\n",
       "      <td>114.897996</td>\n",
       "      <td>12.6</td>\n",
       "      <td>10.5</td>\n",
       "      <td>88.3</td>\n",
       "      <td>7.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014-01-01 02:00:00</td>\n",
       "      <td>66.20412</td>\n",
       "      <td>114.819072</td>\n",
       "      <td>12.9</td>\n",
       "      <td>10.3</td>\n",
       "      <td>87.3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014-01-01 03:00:00</td>\n",
       "      <td>67.27316</td>\n",
       "      <td>114.491295</td>\n",
       "      <td>13.1</td>\n",
       "      <td>10.2</td>\n",
       "      <td>86.2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1020.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        civil  south_tower  wt_temp  wt_tmpap  wt_hr  \\\n",
       "timestamp                                                              \n",
       "2014-01-01 01:00:00  65.99413   114.897996     12.6      10.5   88.3   \n",
       "2014-01-01 02:00:00  66.20412   114.819072     12.9      10.3   87.3   \n",
       "2014-01-01 03:00:00  67.27316   114.491295     13.1      10.2   86.2   \n",
       "\n",
       "                     wt_max_windgust  wt_mean_windspd  wt_mean_pres  \\\n",
       "timestamp                                                             \n",
       "2014-01-01 01:00:00              7.3              3.4        1021.0   \n",
       "2014-01-01 02:00:00              7.8              4.0        1021.0   \n",
       "2014-01-01 03:00:00              8.6              4.6        1020.8   \n",
       "\n",
       "                     wt_mean_solarrad  wt_rain_day  t_hour  t_month  \\\n",
       "timestamp                                                             \n",
       "2014-01-01 01:00:00               0.6          4.9       1        1   \n",
       "2014-01-01 02:00:00               0.7          4.9       2        1   \n",
       "2014-01-01 03:00:00               0.7          5.0       3        1   \n",
       "\n",
       "                     t_dayofweek  t_year  miss_civil  miss_south_tower  \\\n",
       "timestamp                                                                \n",
       "2014-01-01 01:00:00            2    2014           0                 0   \n",
       "2014-01-01 02:00:00            2    2014           0                 0   \n",
       "2014-01-01 03:00:00            2    2014           0                 0   \n",
       "\n",
       "                     miss_wt  \n",
       "timestamp                     \n",
       "2014-01-01 01:00:00        0  \n",
       "2014-01-01 02:00:00        0  \n",
       "2014-01-01 03:00:00        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To overcome the missing data, a study has been conducted to measure the accuracy of different imputation strategies.\n",
    "\n",
    "After an extended review of previous used imputation models, two different models were chosen:\n",
    "- Multivariate imputation by chained equations - [MICE](https://github.com/eltonlaw/impyute);\n",
    "- Miss Forest - [MF](https://pypi.org/project/missingpy/).\n",
    "\n",
    "\n",
    "Both models impute values multiple times, which is known as multiple imputation technique. Altought it is more computational expensive it outperforms in most case scenarios the single imputation technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/Data_Imputation_Study_Diagram.PNG\" width=\"500\" height=\"200\" align=\"center\"/>\n",
    "<center> Fig.1 - Data Imputation Study - Diagram <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conduct this study, the process represented in Fig.1 was performed. This process was done separately for **ECD** and **WCD**, since both models are ruled by the multivariate approach which may lead to an exchange of information between each data set type and a consequent data leakage. This process can be broken down into five main steps:\n",
    "\n",
    "1. From the entire data set, a selection of the maximum consecutive missing values of each feature was performed, denoted as **target** (Tab.1) This selection was motivated by the increased difficulty of imputing wide ranges of missing values;\n",
    "\n",
    "\n",
    "2. The data from the year of **2014** was chosen, since it exhibits the lowest number of missing values. The missing values from the adopted year were dropped and the rest of the data was used as a baseline data set to test the different imputation models;\n",
    "\n",
    "\n",
    "3. A random generation of artificial missing data was performed for each feature based on the **target** (Tab.1) in the baseline data set. Regardless the randomness of this part of the process, when the **WCD** was evaluated, the gaps (missing values) were generated in parallel, in attempt to replicate the real situation;\n",
    "\n",
    "\n",
    "4. Both models (**MICE** and **MF**), were separately applied, filling the missing values with the correspondent predictions;\n",
    "\n",
    "\n",
    "5. The imputed values were then compared with the real ones, stored in step 3. The evaluation of the models per feature was conducted using several error metrics. Afterwards, the baseline data set predictions were set back to the real values;\n",
    "\n",
    "\n",
    "\n",
    "6. **Steps 3 to 4** were repeated for **10 cycles** to ensure that the models performed the imputation in different times of the year. At the end, the **mean error** was calculated per feature to evaluate the imputation models used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps 1 and 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:09:49.560197Z",
     "start_time": "2020-06-04T16:09:49.299891Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Steps 1 and 2\n",
    "\n",
    "# Target Calculation\n",
    "def consecutive_nan(data, important=True):\n",
    "    '''\n",
    "    Function to call\n",
    "    INPUT: Data; \n",
    "           important is set to True it will show the max consecutive NaN for all the features, \n",
    "           otherwise only the important ones with missing values.\n",
    "    OUTPUT: Dictionary with the maximum missing values per feature\n",
    "    '''\n",
    "    columns = data.columns\n",
    "    list_building = []\n",
    "    list_columns = []\n",
    "    for i in range(len(columns)):\n",
    "        list_building.append(consecutive_true(data, columns[i]))\n",
    "        list_columns.append(columns[i])\n",
    "        \n",
    "    missing_values = dict(zip(list_columns, list_building))\n",
    "\n",
    "    if important==True:\n",
    "        missing_values = clean_target(missing_values)\n",
    "    \n",
    "    return missing_values\n",
    "\n",
    "def consecutive_true(data, building):\n",
    "    data = data[building].isna()\n",
    "    longest = 0\n",
    "    current = 0\n",
    "    for num in data:\n",
    "        if num == True:\n",
    "            current += 1\n",
    "        else:\n",
    "            longest = max(longest, current)\n",
    "            current = 0\n",
    "\n",
    "    return max(longest, current)\n",
    "\n",
    "def clean_target(target):\n",
    "    clean_target = list() \n",
    "\n",
    "    # Iterate over the dict and delete keys in the list\n",
    "    for (key, value) in target.items() :\n",
    "        if value == 0:\n",
    "            clean_target.append(key)\n",
    "\n",
    "    # Iterate over the list and delete corresponding key from dictionary\n",
    "    for key in clean_target:\n",
    "        if key in target:\n",
    "            del target[key]\n",
    "    return target\n",
    "\n",
    "target = consecutive_nan(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:09:49.569198Z",
     "start_time": "2020-06-04T16:09:49.563219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'civil': 148,\n",
       " 'south_tower': 88,\n",
       " 'wt_temp': 1165,\n",
       " 'wt_tmpap': 1165,\n",
       " 'wt_hr': 1165,\n",
       " 'wt_max_windgust': 1165,\n",
       " 'wt_mean_windspd': 1165,\n",
       " 'wt_mean_pres': 1165,\n",
       " 'wt_mean_solarrad': 1165,\n",
       " 'wt_rain_day': 1165}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps 3, 4, 5 and 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:09:49.582138Z",
     "start_time": "2020-06-04T16:09:49.572191Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_mean_errors(target, number_samples, buildings):\n",
    "    '''\n",
    "    INPUT:\n",
    "        target - dict - previous calculated through consecutive_nan function\n",
    "        number_samples - int - number of cycles to impute - higher number - leads to a more solid evaluation\n",
    "        buildings  - bool - True: buildings imputation \n",
    "                            False: weather conditions imputation\n",
    "                         \n",
    "    '''\n",
    "    # Creation of the matrix\n",
    "    if buildings == True:\n",
    "        target = dict(list(target.items())[:2])\n",
    "    else:\n",
    "        target = dict(list(target.items())[-8:])\n",
    "        \n",
    "    sum_matrix = np.zeros((len(target), 4))\n",
    "   \n",
    "    RF_mean_error = imputation(sum_matrix,target, number_samples, buildings, model_name='RF')\n",
    "    MICE_mean_error = imputation(sum_matrix,target, number_samples, buildings, model_name='MICE')\n",
    "    MEAN_mean_error = imputation(sum_matrix, target, number_samples, buildings, model_name='MEAN')\n",
    " \n",
    "    return RF_mean_error, MICE_mean_error, MEAN_mean_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:09:49.613055Z",
     "start_time": "2020-06-04T16:09:49.585129Z"
    }
   },
   "outputs": [],
   "source": [
    "def imputation(sum_matrix, target, number_samples, buildings, model_name):\n",
    "    '''\n",
    "    INPUT:\n",
    "        sum_matrix - zero matrix to add errors of imputation per number_samples\n",
    "        target - dict - with the maximum consecutive missing values of each column\n",
    "        number_samples - Int - number of cycles to test\n",
    "        buildings - Bool - True: buildings imputation \n",
    "                           False: weather conditions imputation\n",
    "        model_name - Str - 'RF': MissForest Model\n",
    "                           'MICE': Multiple Imputation by Chained Equation Model\n",
    "                           'MEAN': Uses the mean of the available years at the same hour and month\n",
    "                       \n",
    "    OUTPUT:\n",
    "        mean_matrix_dt - pd.DataFrame - Mean errors of imputed features       \n",
    "    \n",
    "    '''\n",
    "       \n",
    "    # Starting the training\n",
    "    print(20*'-'+f' STARTING {model_name} IMPUTATION '+20*'-')\n",
    "    print('\\n')\n",
    "    \n",
    "    cycle=0\n",
    "    \n",
    "    # Iterate over a random missing value position\n",
    "    for n in range(number_samples):\n",
    "\n",
    "        # Refresh DATA - 2014 only - year with less missing data\n",
    "        # Dataframe of 2017 and 2018 for MEAN_imputation model (model_name = 'MEAN')\n",
    "        dt = pd.read_csv('Preprocessed_Data/_01_dt_00.csv', index_col='timestamp', parse_dates=[0], header=0)\n",
    "        dt_ = dt.copy()\n",
    "        dt = dt['2014'].dropna()\n",
    "        dt_2017_18 = dt_[dt_.index.year.isin(['2017', '2018'])]\n",
    "        \n",
    "        # Evaluation of Buildings or Weather Conditions\n",
    "        if buildings == True:\n",
    "            features = [c for c in list(dt.columns) if c == 'civil' or c =='south_tower' or c.startswith('t_')]            \n",
    "        else:\n",
    "            features = [c for c in list(dt.columns) if c.startswith('wt_') or c.startswith('t_')]\n",
    "            \n",
    "        dt = dt[features]\n",
    "        dt_2017_18 = dt_2017_18[features]\n",
    "\n",
    "        # Create random missing values\n",
    "        print('Random Artificial Missing Values Creation')\n",
    "        col_create_NaN_target(dt, target, n)\n",
    "\n",
    "        # Apply models\n",
    "        if model_name == 'RF':\n",
    "            imputation = RF_imputation(dt)\n",
    "            \n",
    "        elif model_name == 'MICE':\n",
    "            imputation = MICE_imputation(dt)\n",
    "            #sum_matrix = MICE_imputation(sum_matrix, dt, target, model_name, n)\n",
    "            \n",
    "        elif model_name == 'MEAN':\n",
    "            imputation = MEAN_imputation(dt, dt_2017_18)\n",
    "            #sum_matrix = MEAN_imputation(sum_matrix, dt, dt_2017_18, target, model_name, n)\n",
    "\n",
    "    \n",
    "        # Calculate Error per column\n",
    "        imputation_error = error_per_column(dt, imputation, target, model_name, n)\n",
    "\n",
    "        # Add to a common matrix\n",
    "        sum_matrix += imputation_error.values[:, 1:].astype('float')\n",
    "        \n",
    "        # End of one cycle\n",
    "        cycle += 1\n",
    "        print(20*\"-\"+\" \"+str(cycle)+\"/10 \"+\"Cycle finished \"+20*\"-\")\n",
    "\n",
    "    # Calculate mean    \n",
    "    mean_matrix = sum_matrix/number_samples\n",
    "    mean_matrix_dt = pd.DataFrame(data=mean_matrix, index=array(dt.columns)[:len(target)],columns=['CV(%)','RMSE', 'MAPE','R_square'])\n",
    "    \n",
    "    # Save Dataframe\n",
    "    if buildings == True:\n",
    "        mean_matrix_dt.to_csv('01-01-Imputation_Data/'+model_name+'/mean_error/buildings_mean_with_'+str(number_samples)+'.csv')\n",
    "    else:\n",
    "        mean_matrix_dt.to_csv('01-01-Imputation_Data/'+model_name+'/mean_error/wt_mean_with_'+str(number_samples)+'.csv')\n",
    "    \n",
    "    print(mean_matrix_dt)\n",
    "    print('\\n')\n",
    "    return mean_matrix_dt\n",
    "\n",
    "def RF_imputation(dt):\n",
    "    '''\n",
    "    INPUT:\n",
    "        dt - DataFrame for imputation\n",
    "    OUTPUT:\n",
    "        rf_imputation - DataFrame imputed\n",
    "    '''\n",
    "    \n",
    "    # Create model\n",
    "    rf_imputer = MissForest(max_iter=10, n_estimators=100)\n",
    "    \n",
    "    # Fit and Transform model\n",
    "    rf_imputation = rf_imputer.fit_transform(dt)\n",
    "    rf_imputation = pd.DataFrame(data=rf_imputation,index=dt.index,columns=dt.columns)\n",
    "    \n",
    "    return rf_imputation\n",
    "\n",
    "def MICE_imputation(dt):\n",
    "    '''\n",
    "    INPUT:\n",
    "        dt - DataFrame for imputation\n",
    "    OUTPUT:\n",
    "        mice_imputation - DataFrame imputed\n",
    "    '''\n",
    "    # Train and Fit\n",
    "    mice_imputer = mice(dt.values)\n",
    "    \n",
    "    # dataframe and merge\n",
    "    mice_imputation = pd.DataFrame(data=mice_imputer,index=dt.index,columns=dt.columns)\n",
    "    \n",
    "    return mice_imputation\n",
    "\n",
    "def MEAN_imputation(dt, dt_2017_18):\n",
    "    '''\n",
    "    INPUT:\n",
    "        dt - DataFrame for imputation\n",
    "        dt_2017_18 - To be used to catch mean values\n",
    "    OUTPUT:\n",
    "        mean_imputation - DataFrame imputed\n",
    "    '''\n",
    "    \n",
    "    # Unique years\n",
    "    years = dt.index.year.unique()\n",
    "    \n",
    "    # Columns with missing data\n",
    "    missing_columns = dt.columns[dt.isnull().any()]\n",
    "    # Iterate over each column with missing data\n",
    "    for column_name in missing_columns:\n",
    "        \n",
    "        for i in range(len(dt)):\n",
    "            column = dt[column_name][i]\n",
    "            idx = dt.index[i]      \n",
    "            hour = idx.hour\n",
    "            month = idx.month\n",
    "            year = idx.year\n",
    "\n",
    "            if math.isnan(column) == True:\n",
    "\n",
    "                dt_month = dt_2017_18.loc[dt_2017_18['t_month'] == month]\n",
    "                dt_hour = dt_month.loc[dt_month['t_hour'] == hour]\n",
    "                impute = dt_hour[column_name].mean()\n",
    "        \n",
    "                dt[column_name][i] = impute               \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:09:49.640981Z",
     "start_time": "2020-06-04T16:09:49.617045Z"
    },
    "code_folding": [
     0,
     11,
     49,
     74
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Extra functions:\n",
    "- To artificial create missing values (col_create_NaN_target() + create_NaN_target())\n",
    "- To measure the error (error_per_column() + calculate_error())\n",
    "\n",
    "''' \n",
    "def col_create_NaN_target(data, target, n):\n",
    "    '''\n",
    "    Creates artificial random missing values\n",
    "    alongside with create_NaN_target function\n",
    "    '''\n",
    "    \n",
    "    building, missing = zip(*target.items())\n",
    "\n",
    "    for i in range(len(target)):\n",
    "        data = create_NaN_target(data, building[i], missing[i], n)\n",
    "        \n",
    "def create_NaN_target(data, column, length, n):\n",
    "    \n",
    "    # Because weather missing values are in the same position\n",
    "    same_starting = ['wt_temp', 'wt_tmpap','wt_hr', 'wt_max_windgust',\n",
    "                     'wt_mean_windspd', 'wt_mean_pres','wt_mean_solarrad', 'wt_rain_day']\n",
    "    \n",
    "    if column in same_starting:\n",
    "        random.seed(n)\n",
    "        num = randint(0, len(data)-length)\n",
    "        \n",
    "    elif column == 'civil':\n",
    "        random.seed(n)\n",
    "        num = randint(0, len(data)-length)\n",
    "    elif column == 'south_tower':\n",
    "        random.seed(n+1)\n",
    "        num = randint(0, len(data)-length)\n",
    "    \n",
    "    # Creation of lists\n",
    "    list_index=[]\n",
    "    list_test=[]\n",
    "    \n",
    "    # For loop to remove data\n",
    "    for i in range(len(data)):\n",
    "        if i in range(num, num+length):\n",
    "            \n",
    "            list_test.append(data[column][i])\n",
    "            list_index.append(data.index[i])\n",
    "            data[column][i] = np.nan\n",
    "    \n",
    "    # Creation of a test dataframe\n",
    "    test = pd.DataFrame(data=list_test, index=list_index, columns=[column+'_true'])\n",
    "    \n",
    "    # Save to check the accuracy later\n",
    "    filename = '01-01-Imputation_Data/'+column+'_true.csv'\n",
    "    test.to_csv(filename)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def error_per_column(dt, dt_pred, target, model_used, n):\n",
    "    \n",
    "    building, missing = zip(*target.items())\n",
    "    error = []\n",
    "    \n",
    "    for i in range(len(target)):\n",
    "        filename = '01-01-Imputation_Data/'+building[i]+'_true.csv'\n",
    "    \n",
    "        dt_true = pd.read_csv(filename,index_col=[0],parse_dates=[0], header=0)\n",
    "        dt_both = pd.merge(dt_true, dt_pred[building[i]], how = 'inner', left_index=True, right_index=True)\n",
    "        \n",
    "        # Save dataframe to check later\n",
    "        filename = '01-01-Imputation_Data/'+model_used+'/'+building[i]+'_'+str(n)+'.csv'\n",
    "        dt_both.to_csv(filename)\n",
    "    \n",
    "        # Calculate error and append\n",
    "        error_column = calculate_error(dt_both)\n",
    "        error_column.insert(0, building[i]) \n",
    "        # Append to a list of lists\n",
    "        error.append(error_column)\n",
    "    \n",
    "    \n",
    "    error = pd.DataFrame(data=error, columns=['building','CV(%)','RMSE', 'MAPE','R^2'])\n",
    "    return error\n",
    "\n",
    "def calculate_error(to_check):\n",
    "    \n",
    "    arr = to_check.values\n",
    "    y_true = arr[:,0]\n",
    "    y_pred = arr[:,1]\n",
    "       \n",
    "    cv = (math.sqrt(mean_squared_error(y_true, y_pred))/mean(y_true))*100\n",
    "    rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = tsmetrics.mean_absolute_percentage_error(y_true, y_pred, min_val=0.001)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    error_column = [cv, rmse, mape, r2]\n",
    "\n",
    "    return error_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Imputation & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BUILDINGS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:12:04.193054Z",
     "start_time": "2020-06-04T16:09:49.645966Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- STARTING RF IMPUTATION --------------------\n",
      "\n",
      "\n",
      "Random Artificial Missing Values Creation\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "-------------------- 1/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "-------------------- 2/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "-------------------- 3/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "-------------------- 4/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "-------------------- 5/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "-------------------- 6/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "-------------------- 7/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "-------------------- 8/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "-------------------- 9/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "-------------------- 10/10 Cycle finished --------------------\n",
      "                 CV(%)       RMSE       MAPE  R_square\n",
      "civil        22.349029  41.183420  16.079706  0.764470\n",
      "south_tower  24.290159  43.364051  13.830029 -0.158373\n",
      "\n",
      "\n",
      "-------------------- STARTING MICE IMPUTATION --------------------\n",
      "\n",
      "\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 1/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 2/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 3/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 4/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 5/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 6/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 7/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 8/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 9/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 10/10 Cycle finished --------------------\n",
      "                 CV(%)       RMSE       MAPE  R_square\n",
      "civil        51.291157  96.003204  40.162080  1.427390\n",
      "south_tower  52.346519  93.701198  30.923964 -0.133108\n",
      "\n",
      "\n",
      "-------------------- STARTING MEAN IMPUTATION --------------------\n",
      "\n",
      "\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 1/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 2/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 3/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 4/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 5/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 6/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 7/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 8/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 9/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 10/10 Cycle finished --------------------\n",
      "                 CV(%)        RMSE       MAPE  R_square\n",
      "civil        95.870662  180.590455  77.039923  1.711951\n",
      "south_tower  96.348512  171.181874  67.150332 -3.025401\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RF_mean_error_b, MICE_mean_error_b, MEAN_mean_error_b  = calculate_mean_errors(target, 10, buildings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WEATHER CONDITIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:37:47.027373Z",
     "start_time": "2020-06-04T16:12:04.196934Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- STARTING RF IMPUTATION --------------------\n",
      "\n",
      "\n",
      "Random Artificial Missing Values Creation\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "-------------------- 1/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "-------------------- 2/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "-------------------- 3/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "-------------------- 4/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 8\n",
      "Iteration: 9\n",
      "-------------------- 5/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "-------------------- 6/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "-------------------- 7/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "-------------------- 8/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "-------------------- 9/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "-------------------- 10/10 Cycle finished --------------------\n",
      "                       CV(%)        RMSE           MAPE  R_square\n",
      "wt_temp            26.636761    4.314526      22.887059 -0.926883\n",
      "wt_tmpap           38.284619    4.860928      37.196433 -1.073045\n",
      "wt_hr              29.919681   18.720830      30.663055 -0.558896\n",
      "wt_max_windgust    45.645272    3.523091    5248.923798 -0.122655\n",
      "wt_mean_windspd    50.262833    2.140818    4027.168808 -0.102955\n",
      "wt_mean_pres        0.724786    7.367914       0.571990 -1.086546\n",
      "wt_mean_solarrad   97.751229  191.826693    1279.216796  0.458870\n",
      "wt_rain_day       629.208454    4.370096  129753.790260 -4.868104\n",
      "\n",
      "\n",
      "-------------------- STARTING MICE IMPUTATION --------------------\n",
      "\n",
      "\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 1/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 2/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 3/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 4/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 5/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 6/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 7/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 8/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 9/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 10/10 Cycle finished --------------------\n",
      "                        CV(%)        RMSE           MAPE  R_square\n",
      "wt_temp             53.283056    8.603109      46.003363 -1.851584\n",
      "wt_tmpap            76.135699    9.654823      73.765875 -2.093397\n",
      "wt_hr               54.471647   34.118909      55.658560 -0.607354\n",
      "wt_max_windgust     89.640662    6.923662   10302.781663 -0.167409\n",
      "wt_mean_windspd     99.387017    4.236321    8025.653622 -0.160031\n",
      "wt_mean_pres         1.384128   14.069503       1.077222 -1.314922\n",
      "wt_mean_solarrad   241.738002  459.280820  204640.424751  0.363302\n",
      "wt_rain_day       1032.437059    7.652506  223478.297664 -5.540640\n",
      "\n",
      "\n",
      "-------------------- STARTING MEAN IMPUTATION --------------------\n",
      "\n",
      "\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 1/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 2/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 3/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 4/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 5/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 6/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 7/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 8/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 9/10 Cycle finished --------------------\n",
      "Random Artificial Missing Values Creation\n",
      "-------------------- 10/10 Cycle finished --------------------\n",
      "                        CV(%)        RMSE           MAPE  R_square\n",
      "wt_temp             68.112095   10.988903      57.439668 -1.393268\n",
      "wt_tmpap           103.142814   13.063299     100.318308 -2.090580\n",
      "wt_hr               77.623266   48.724697      76.461248 -0.571988\n",
      "wt_max_windgust    163.939987   12.716556   12343.126096 -2.304074\n",
      "wt_mean_windspd    176.311844    7.539100    9574.893294 -1.820131\n",
      "wt_mean_pres         2.060003   20.938996       1.609434 -1.629136\n",
      "wt_mean_solarrad   306.333752  569.245354  207810.682279  1.143976\n",
      "wt_rain_day       1369.330403   10.862668  266292.831055 -5.568789\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RF_mean_error_wt, MICE_mean_error_wt, MEAN_mean_error_wt  = calculate_mean_errors(target, 10, buildings=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this study we can conclude that although the **Miss Forest** (RF) model showed, in general, greater accuracy in each of the data set types (WCD and ECD) when compared with **MICE**, the **gap in WCD** was still with the undesirable imputation values in terms of the expected seasonality and trend.\n",
    "\n",
    "\n",
    "To address that, the third method **MEAN_imputation** was developed. This method basically fills each feature independently with the known values from the available years, using the correspondent mean of the same month and hour.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Data Imputation Strategy - Creation of different datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step of **Data Treatment** consists in the creation of three different dataframes that differ in the adopted strategies for the existing missing values.\n",
    "\n",
    "Therefore, the first strategy common to each of the data sets, named as `dt_01`, `dt_02`, and `dt_03`, was a **three hours linear interpolation**, which is of great use in time series data. After that, the three dataframes differ from one to another, as it is described below:\n",
    "\n",
    "* `dt_01`\n",
    "    - Drop every NaN values\n",
    "* `dt_02`\n",
    "    - ECD Imputation by **Miss Forest** \n",
    "    - Drop WCD NaN values\n",
    "* `dt_03`\n",
    "    - ECD Imputation by **Miss Forest**\n",
    "    - WCD Imputation by **MEAN_Imputation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>civil</th>\n",
       "      <th>south_tower</th>\n",
       "      <th>wt_temp</th>\n",
       "      <th>wt_tmpap</th>\n",
       "      <th>wt_hr</th>\n",
       "      <th>wt_max_windgust</th>\n",
       "      <th>wt_mean_windspd</th>\n",
       "      <th>wt_mean_pres</th>\n",
       "      <th>wt_mean_solarrad</th>\n",
       "      <th>wt_rain_day</th>\n",
       "      <th>t_hour</th>\n",
       "      <th>t_month</th>\n",
       "      <th>t_dayofweek</th>\n",
       "      <th>t_year</th>\n",
       "      <th>miss_civil</th>\n",
       "      <th>miss_south_tower</th>\n",
       "      <th>miss_wt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-01 01:00:00</th>\n",
       "      <td>65.99413</td>\n",
       "      <td>114.897996</td>\n",
       "      <td>12.6</td>\n",
       "      <td>10.5</td>\n",
       "      <td>88.3</td>\n",
       "      <td>7.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 02:00:00</th>\n",
       "      <td>66.20412</td>\n",
       "      <td>114.819072</td>\n",
       "      <td>12.9</td>\n",
       "      <td>10.3</td>\n",
       "      <td>87.3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 03:00:00</th>\n",
       "      <td>67.27316</td>\n",
       "      <td>114.491295</td>\n",
       "      <td>13.1</td>\n",
       "      <td>10.2</td>\n",
       "      <td>86.2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1020.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 04:00:00</th>\n",
       "      <td>65.53597</td>\n",
       "      <td>115.337955</td>\n",
       "      <td>13.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>85.9</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 05:00:00</th>\n",
       "      <td>68.03676</td>\n",
       "      <td>114.201319</td>\n",
       "      <td>13.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>85.2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        civil  south_tower  wt_temp  wt_tmpap  wt_hr  \\\n",
       "timestamp                                                              \n",
       "2014-01-01 01:00:00  65.99413   114.897996     12.6      10.5   88.3   \n",
       "2014-01-01 02:00:00  66.20412   114.819072     12.9      10.3   87.3   \n",
       "2014-01-01 03:00:00  67.27316   114.491295     13.1      10.2   86.2   \n",
       "2014-01-01 04:00:00  65.53597   115.337955     13.2      10.0   85.9   \n",
       "2014-01-01 05:00:00  68.03676   114.201319     13.2      10.2   85.2   \n",
       "\n",
       "                     wt_max_windgust  wt_mean_windspd  wt_mean_pres  \\\n",
       "timestamp                                                             \n",
       "2014-01-01 01:00:00              7.3              3.4        1021.0   \n",
       "2014-01-01 02:00:00              7.8              4.0        1021.0   \n",
       "2014-01-01 03:00:00              8.6              4.6        1020.8   \n",
       "2014-01-01 04:00:00              9.3              4.9        1020.0   \n",
       "2014-01-01 05:00:00              8.6              4.6        1020.0   \n",
       "\n",
       "                     wt_mean_solarrad  wt_rain_day  t_hour  t_month  \\\n",
       "timestamp                                                             \n",
       "2014-01-01 01:00:00               0.6          4.9       1        1   \n",
       "2014-01-01 02:00:00               0.7          4.9       2        1   \n",
       "2014-01-01 03:00:00               0.7          5.0       3        1   \n",
       "2014-01-01 04:00:00               0.8          5.0       4        1   \n",
       "2014-01-01 05:00:00               0.6          5.0       5        1   \n",
       "\n",
       "                     t_dayofweek  t_year  miss_civil  miss_south_tower  \\\n",
       "timestamp                                                                \n",
       "2014-01-01 01:00:00            2    2014           0                 0   \n",
       "2014-01-01 02:00:00            2    2014           0                 0   \n",
       "2014-01-01 03:00:00            2    2014           0                 0   \n",
       "2014-01-01 04:00:00            2    2014           0                 0   \n",
       "2014-01-01 05:00:00            2    2014           0                 0   \n",
       "\n",
       "                     miss_wt  \n",
       "timestamp                     \n",
       "2014-01-01 01:00:00        0  \n",
       "2014-01-01 02:00:00        0  \n",
       "2014-01-01 03:00:00        0  \n",
       "2014-01-01 04:00:00        0  \n",
       "2014-01-01 05:00:00        0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = pd.read_csv('Preprocessed_Data/_01_dt_00.csv',index_col=[0],parse_dates=[0], header=0)\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "civil                157\n",
       "south_tower           96\n",
       "wt_temp             2357\n",
       "wt_tmpap            2357\n",
       "wt_hr               2357\n",
       "wt_max_windgust     2357\n",
       "wt_mean_windspd     2357\n",
       "wt_mean_pres        2357\n",
       "wt_mean_solarrad    2357\n",
       "wt_rain_day         2357\n",
       "t_hour                 0\n",
       "t_month                0\n",
       "t_dayofweek            0\n",
       "t_year                 0\n",
       "miss_civil             0\n",
       "miss_south_tower       0\n",
       "miss_wt                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dt_01 : Linear Interpolation + Drop every NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt_01 = dt.interpolate(method='linear', limit=3).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_01.to_csv('Preprocessed_Data/_01_dt_01.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dt_02 : Linear Interpolation + ECD Miss Forest + Drop WCD NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns selection\n",
    "def select_columns(df, prefix_catch):\n",
    "    list_col = []   \n",
    "    for prefix in prefix_catch:\n",
    "        cols = select_by_prefix(df, prefix)\n",
    "        list_col.extend(cols)\n",
    "    return list_col\n",
    "\n",
    "def select_by_prefix(dt, d_type):\n",
    "    return list(dt.filter(regex='^'+d_type, axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MissForest_buildings(dt):\n",
    "    ## Split the dataframes to apply multi-imputation\n",
    "\n",
    "    ## Buildings\n",
    "    dt_buildings = dt[['civil', 'south_tower']]\n",
    "\n",
    "    ## Weather and other features\n",
    "    dt_weather = dt[select_columns(dt,['wt_','miss','t_'])]\n",
    "\n",
    "    ## BUILDINGS\n",
    "    mf = MissForest(max_iter=10, n_estimators=100)\n",
    "    # Fit and Fill the dataframe\n",
    "    dt_buildings_mf = mf.fit_transform(dt_buildings)\n",
    "    # Create the dataframe again with the Fill Data\n",
    "    dt_buildings_mf = pd.DataFrame(data=dt_buildings_mf,index=dt_buildings.index,columns=dt_buildings.columns)\n",
    "\n",
    "\n",
    "    # Merge the Weather and other features and Buildings Columns\n",
    "    dt = pd.merge(dt_buildings_mf,dt_weather, how='inner', left_index=True, right_index=True)\n",
    "    \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n"
     ]
    }
   ],
   "source": [
    "# Linear Interpolation\n",
    "dt_02 = dt.interpolate(method='linear', limit=3)\n",
    "# Buildings Imputation\n",
    "dt_02 = MissForest_buildings(dt_02)\n",
    "# Drop weather values\n",
    "dt_02 = dt_02.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_02.to_csv('Preprocessed_Data/_01_dt_02.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dt_03 : Linear Interpolation + ECD Miss Forest + WCD MEAN_Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n"
     ]
    }
   ],
   "source": [
    "# Linear Interpolation\n",
    "dt_03 = dt.interpolate(method='linear', limit=3)\n",
    "\n",
    "# ECD Imputation\n",
    "dt_03 = MissForest_buildings(dt_03)\n",
    "\n",
    "# WCD Imputation with MEAN_imputation\n",
    "dt_no_missing = dt_03.loc[dt_03['miss_wt'] == 0]\n",
    "dt_03 = MEAN_imputation(dt_03, dt_no_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_03.to_csv('Preprocessed_Data/_01_dt_03.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of the imputation techniques applied per data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/summary_imputation.PNG\" width=\"900\" height=\"200\" align=\"center\"/>\n",
    "<center> Tab.1 -Summary of the imputation techniques applied per data set <center>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "264px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
