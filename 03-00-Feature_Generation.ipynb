{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Extra packages\n",
    "from datetime import date\n",
    "import holidays\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation\n",
    "\n",
    "The feature generation step is responsible to created new features that somehow offer additional information to the machine learning models towards the enhancement of their output predictions. In the scope of this work, the output is the energy consumption of each building, therefore, each new feature most be generated in attempt to describe its behavior and particular characteristics.\n",
    "\n",
    "In this study, the new features, may be grouped according to what they are based on, therefore, there are **three main categories**:\n",
    "\n",
    "- Time\n",
    "- Calendar\n",
    "- Energy consumption. \n",
    "\n",
    "The first includes every new feature that was time dependent, the second group of features was based on the national and academic calendar, and lastly, the third group generates features that were based on each building own consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://imgur.com/g1VJ0Dd.png\" width=\"800\" height=\"500\" align=\"center\"/>\n",
    "<center> Fig.1 - Data Imputation Study - Diagram <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to call all the data sets that resulted from the **Data Imputation Strategy** of notebook **01-01-Data_Treatment**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_01 = pd.read_csv('Preprocessed_Data/_01_dt_01.csv', index_col=[0], parse_dates=[0], header=0)\n",
    "dt_02 = pd.read_csv('Preprocessed_Data/_01_dt_02.csv', index_col=[0], parse_dates=[0], header=0)\n",
    "dt_03 = pd.read_csv('Preprocessed_Data/_01_dt_03.csv', index_col=[0], parse_dates=[0], header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This group of new features, was supported by the patterns encounter in each of the temporal partitions performed in the consumption analysis, in the previous notebook **02-00-EDA-Energy_Consumption_Analysis**. In attempt to offer to the forecasting models the possibility to distinguish those patterns three features were generated with integers values that differ depending on the temporal partition,\n",
    "\n",
    "Example: for monthly partition, integers from 1 to 12 were set in the new feature. The three new features were named after each temporal partition, specifically **t_month**, **t_dayofweek**, and **t_hour**.\n",
    "\n",
    "They were already created in the first notebook **01-00-Data_Treatment** to ease the analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['civil', 'south_tower', 'wt_temp', 'wt_tmpap', 'wt_hr',\n",
       "       'wt_max_windgust', 'wt_mean_windspd', 'wt_mean_pres',\n",
       "       'wt_mean_solarrad', 'wt_rain_day', 't_hour', 't_month', 't_dayofweek',\n",
       "       't_year', 'miss_civil', 'miss_south_tower', 'miss_wt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_01.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the absence of each building real occupancy data, this category was implemented. Basically attempts to replicate the real occupancy per day, with two different features. For that, each of the features use integer values, **levels**, that quantify the expected daily occupancy rate, being the lowest level the one that has the smallest occupancy rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Workday Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first feature, named as **s_workday**, specifies the type of day in three distinguished levels, defined\n",
    "as:\n",
    "- **Level 0** - represents weekends and the two weeks yearly summer break of all campus facilities;\n",
    "- **Level 1** - identifies the holidays that occur during the week. This level, although representing\n",
    "non-working days, in the case of an institutional buildings, their rate of occupancy is, usually,\n",
    "in-between the other two levels;\n",
    "- **Level 2** - as the last level in s_workday feature, represents the normal working days, where\n",
    "the occupancy rate is expected to be the highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_workday(dt):\n",
    "    '''\n",
    "    Creates a new column that quantifies the type of day in three different levels. \n",
    "    It uses holiday package to know which day is an national holiday in Portugal.\n",
    "    \n",
    "    Input: DataFrame\n",
    "    Output: DataFrame\n",
    "    '''\n",
    "    \n",
    "    # Instantiate Portugal object\n",
    "    port_holidays = holidays.PortugalExt()\n",
    "    \n",
    "    # Adapt object\n",
    "    # Remove 26th holiday - once all the buildings behave like it's a normal working day\n",
    "    for year in dt['t_year'].unique():\n",
    "        port_holidays.pop(str(year)+'-12-26')\n",
    "    \n",
    "    # Add more holidays to the package\n",
    "    port_holidays.append({'2014-06-19':'Corpo de Deus',\n",
    "                          '2014-10-05':'Implantação da República', \n",
    "                          '2014-10-01':'Dia de Todos os Santos', \n",
    "                          '2014-12-01':'Restauração da Independência'})\n",
    "\n",
    "    # Create new column\n",
    "    dt['s_workday'] = (dt['civil']*0)+2\n",
    "    \n",
    "    # Generation of 1 for holidays and 0 for workdays\n",
    "    x = range(0, len(dt))\n",
    "    for hour in x:    \n",
    "        workday = dt['s_workday'][hour]\n",
    "        weekday = dt['t_dayofweek'][hour]\n",
    "        # Indexing the days - to add more vacations\n",
    "        idx = dt.index[hour]   \n",
    "        d = idx.day\n",
    "        m = idx.month\n",
    "        y = idx.year\n",
    "\n",
    "        # Append holdays\n",
    "        if date(y,m,d) in port_holidays:\n",
    "            dt['s_workday'][hour] = 1\n",
    "            \n",
    "        # Weekend days\n",
    "        elif weekday == 5 or weekday == 6:\n",
    "            dt['s_workday'][hour] = 0\n",
    "    \n",
    "    # Adapt object - Summer Break of Instituto Superior Técnico, Universidade de Lisboa\n",
    "    # 2014 - Summer break\n",
    "    august_14 = pd.date_range(start='2014-08-04', end='2014-08-15')\n",
    "    dt['s_workday'][pd.DatetimeIndex(dt.index.date).isin(august_14)] = 0\n",
    "\n",
    "    # 2017 - Summer break\n",
    "    august_17 = pd.date_range(start='2017-07-31', end='2017-08-11')\n",
    "    dt['s_workday'][pd.DatetimeIndex(dt.index.date).isin(august_17)] = 0\n",
    "\n",
    "    # 2018 - Summer break\n",
    "    august_18 = pd.date_range(start='2018-08-06', end='2018-08-17')\n",
    "    dt['s_workday'][pd.DatetimeIndex(dt.index.date).isin(august_18)] = 0\n",
    "    \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create s_workday feature\n",
    "dt_01 = create_workday(dt_01)\n",
    "dt_02 = create_workday(dt_02)\n",
    "dt_03 = create_workday(dt_03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Section: Workday feature vs. Clusters\n",
    "\n",
    "As promised we are going to check the quality of the s_workday and time features assuming that the clusters previously identified can propertly identify the day type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_aggregation_to_dataset(cl_building_pivot, original_dt, building_name):\n",
    "    \n",
    "    # Drop unnecessary data\n",
    "    cl = cl_building_pivot.reset_index(level='cluster')\n",
    "    cl = cl.drop([building_name], axis = 1)\n",
    "    \n",
    "    # Set again to hourly data - respecting clusters\n",
    "    cl.index = pd.to_datetime(cl.index)\n",
    "    cl = cl.resample('H').pad()\n",
    "    \n",
    "    # Rename column\n",
    "    column_name = building_name+'_cl'\n",
    "       \n",
    "    cl.columns = [column_name]\n",
    "    \n",
    "    # Add column to original dataset\n",
    "    new_dt = pd.merge(original_dt,cl, how='inner', left_index=True, right_index=True)\n",
    "    \n",
    "    return new_dt, cl\n",
    "\n",
    "def workday_season_vs_cluster(dt, building):\n",
    "    \n",
    "    # To know the quantity of clusters\n",
    "    k = len(dt[building+'_cl'].unique())\n",
    "    \n",
    "    # List of percentages\n",
    "    perc = []\n",
    "    \n",
    "    # For loop need\n",
    "    for i in range(k): \n",
    "        # All data from a cluster\n",
    "        cluster = dt[dt[building+'_cl'] == i]\n",
    "        total = len(cluster)\n",
    "\n",
    "        \n",
    "        # Workday\n",
    "        wd = len(cluster[cluster['s_workday']==2])\n",
    "        h = len(cluster[cluster['s_workday']==1])\n",
    "        wk = len(cluster[cluster['s_workday']==0])\n",
    "        \n",
    "        # Season Heating vs. Cooling\n",
    "        heating_season = [1, 2, 3, 4, 11, 12]\n",
    "        heating = len(cluster.loc[cluster['t_month'].isin(heating_season)])\n",
    "        cooling_season = [5, 6, 7, 8, 9, 10]\n",
    "        cooling = len(cluster.loc[cluster['t_month'].isin(cooling_season)])\n",
    "               \n",
    "        # Percentage\n",
    "        perc_wd = round((wd/total)*100, 1)\n",
    "        perc_h = round((h/total)*100, 1)\n",
    "        perc_wk = round((wk/total)*100, 1)\n",
    "        \n",
    "        perc_heat = round((heating/total)*100, 1)\n",
    "        perc_cool = round((cooling/total)*100, 1)\n",
    "        \n",
    "        perc.append(['k='+str(i), perc_wd, perc_h, perc_wk, perc_heat, perc_cool])\n",
    "        \n",
    "    perc_dt = pd.DataFrame(data=perc,columns=['Cluster','workday(%)','holiday(%)','weekend and summer break(%)', 'Heating Season(%)', 'Cooling Season(%)']).set_index('Cluster')\n",
    "        \n",
    "    return perc_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "k_civil_pivot = pd.read_csv('Preprocessed_Data/_02_pivot_civil_clustered.csv', index_col=[0,1], header=[0,1])\n",
    "k_stw_pivot = pd.read_csv('Preprocessed_Data/_02_pivot_stw_clustered.csv', index_col=[0, 1], header=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Civil Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='civil_building'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://imgur.com/PSVhwVF.png\" width=\"800\" height=\"500\" align=\"center\"/>\n",
    "<center> <b>Fig.2</b> - Data Imputation Study - Diagram <center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workday(%)</th>\n",
       "      <th>holiday(%)</th>\n",
       "      <th>weekend and summer break(%)</th>\n",
       "      <th>Heating Season(%)</th>\n",
       "      <th>Cooling Season(%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>k=0</th>\n",
       "      <td>95.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>43.3</td>\n",
       "      <td>56.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k=1</th>\n",
       "      <td>3.8</td>\n",
       "      <td>11.1</td>\n",
       "      <td>85.1</td>\n",
       "      <td>52.6</td>\n",
       "      <td>47.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k=2</th>\n",
       "      <td>99.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>57.6</td>\n",
       "      <td>42.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         workday(%)  holiday(%)  weekend and summer break(%)  \\\n",
       "Cluster                                                        \n",
       "k=0            95.6         2.0                          2.3   \n",
       "k=1             3.8        11.1                         85.1   \n",
       "k=2            99.4         0.0                          0.6   \n",
       "\n",
       "         Heating Season(%)  Cooling Season(%)  \n",
       "Cluster                                        \n",
       "k=0                   43.3               56.7  \n",
       "k=1                   52.6               47.4  \n",
       "k=2                   57.6               42.4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_cl, civil_cl = column_aggregation_to_dataset(k_civil_pivot, dt_01, 'civil')\n",
    "workday_season_vs_cluster(dt_cl, 'civil')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**South tower**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='south_tower'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://imgur.com/m84M0bX.png\" width=\"800\" height=\"500\" align=\"center\"/>\n",
    "<center> <b>Fig.3</b> - South tower building daily consumption patterns defined by k-means algorithm (k=3) <center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workday(%)</th>\n",
       "      <th>holiday(%)</th>\n",
       "      <th>weekend and summer break(%)</th>\n",
       "      <th>Heating Season(%)</th>\n",
       "      <th>Cooling Season(%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>k=0</th>\n",
       "      <td>4.1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>85.3</td>\n",
       "      <td>62.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k=1</th>\n",
       "      <td>98.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>97.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k=2</th>\n",
       "      <td>97.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>88.6</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k=3</th>\n",
       "      <td>26.7</td>\n",
       "      <td>9.8</td>\n",
       "      <td>63.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         workday(%)  holiday(%)  weekend and summer break(%)  \\\n",
       "Cluster                                                        \n",
       "k=0             4.1        10.5                         85.3   \n",
       "k=1            98.1         0.0                          1.9   \n",
       "k=2            97.6         1.6                          0.8   \n",
       "k=3            26.7         9.8                         63.5   \n",
       "\n",
       "         Heating Season(%)  Cooling Season(%)  \n",
       "Cluster                                        \n",
       "k=0                   62.0               38.0  \n",
       "k=1                    2.2               97.8  \n",
       "k=2                   88.6               11.4  \n",
       "k=3                   26.0               74.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_cl, stw_cl = column_aggregation_to_dataset(k_stw_pivot, dt_01, 'south_tower')\n",
    "workday_season_vs_cluster(dt_cl, 'south_tower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the **s_workday** and **time** features are able to define the type of day:\n",
    "\n",
    "- The workday percentage of days in clusters k=0 and k=2 for **Civil building** and also in k=1 and k=2 for **South tower** is almost 100%;\n",
    "- The holiday percentage of days is almost pratically clustered in one cluster (k=2) for **Civil building** and for two clusters (k=0 and k=3) for **South tower**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>NOTE</b>: It is also possible to notice that <b>South Tower</b> is greatly influenced by heating and cooling season as referred earlier in the monthly analysis (<b>02-00-EDA-Energy_Consumption_Analysis</b>), in opposition <b>Civil building</b> that has around 50% of days in cooling and heating season is not influenced at all by different seasons.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Exam Seasons Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second feature, denoted as **s_epochs**, attempts to give the model information about the different types of occupancy occurring when there is exams, classes, and break periods during the [academic calendar](https://conselhopedagogico.tecnico.ulisboa.pt/documentos/calendarios/). For that, also three levels were specified:\n",
    "\n",
    "- **Level 0** - corresponds again, to the lowest rate of occupancy, the break period between semesters;\n",
    "- **Level 1** - identifies the exams period, with no classes;\n",
    "- **Level 2** - refers to the classes period of each of the academic semesters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def different_epochs(dt):\n",
    "    '''\n",
    "    Creates a new column that quantifies the type of day in three different levels, \n",
    "    based on Instituto Superior Técnico Academic Calendar\n",
    "    \n",
    "    Input: DataFrame\n",
    "    Output: DataFrame\n",
    "    '''    \n",
    "    # Create new column\n",
    "    dt['s_epochs'] = dt['civil']*0\n",
    "    \n",
    "    #### 2014\n",
    "    ### CLASS PERIOD\n",
    "    ## 2nd Semester\n",
    "    class_14_2 = pd.date_range(start='2014-02-17', end='2014-05-30')\n",
    "    dt['s_epochs'][pd.DatetimeIndex(dt.index.date).isin(class_14_2)] = 2\n",
    "\n",
    "    # Breaks in 2nd semester\n",
    "    # Carnival\n",
    "    carnival_14 = pd.date_range(start='2014-03-03', end='2014-03-04')\n",
    "    dt['s_epochs'][pd.DatetimeIndex(dt.index.date).isin(carnival_14)] = 0 \n",
    "    # Easter Break\n",
    "    easter_14 = pd.date_range(start='2014-04-13', end='2014-04-20')\n",
    "    dt['s_epochs'][pd.DatetimeIndex(dt.index.date).isin(easter_14)] = 0\n",
    "    \n",
    "    ## 1st Semester\n",
    "    class_14 = pd.date_range(start='2014-09-15', end='2014-12-19')\n",
    "    dt['s_epochs'][pd.DatetimeIndex(dt.index.date).isin(class_14)] = 2\n",
    "\n",
    "        \n",
    "    ## EXAMS PERIOD\n",
    "    # represent all the period, with first and second wave of exams\n",
    "    ## 1st semester\n",
    "    exam_14 = pd.date_range(start='2014-01-03', end='2014-02-01')\n",
    "    dt['s_epochs'][pd.DatetimeIndex(dt.index.date).isin(exam_14)] = 1\n",
    "    \n",
    "    ## 2nd semester\n",
    "    exam_14_2 = pd.date_range(start='2014-06-07', end='2014-07-04')\n",
    "    dt['s_epochs'][pd.DatetimeIndex(dt.index.date).isin(exam_14_2)] = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    #### 2017\n",
    "    ### Class Period\n",
    "    ## 2nd Semester\n",
    "    class_17_2 = pd.date_range(start='2017-02-20', end='2017-06-02')\n",
    "    dt['s_epochs'][pd.DatetimeIndex(dt.index.date).isin(class_17_2)] = 2\n",
    "    \n",
    "    # Breaks in 2nd semester\n",
    "    # Carnival\n",
    "    carnival_17 = pd.date_range(start='2017-02-27', end='2017-02-28')\n",
    "    dt['s_epochs'][pd.DatetimeIndex(dt.index.date).isin(carnival_17)] = 0 \n",
    "    # Easter Break\n",
    "    easter_17 = pd.date_range(start='2017-04-10', end='2017-04-14')\n",
    "    dt['s_epochs'][pd.DatetimeIndex(dt.index.date).isin(easter_17)] = 0\n",
    "    \n",
    "    \n",
    "    ## 1st Semester\n",
    "    class_17_2 = pd.date_range(start='2017-09-18', end='2017-12-15')\n",
    "    dt['s_epochs'][pd.DatetimeIndex(dt.index.date).isin(class_17_2)] = 2\n",
    "\n",
    "\n",
    "    ## EXAMS PERIOD\n",
    "    # represent all the period, with first and second wave of exams\n",
    "    ## 1st semester\n",
    "    exam_17 = pd.date_range(start='2017-01-07', end='2017-02-04')\n",
    "    dt['s_epochs'][pd.DatetimeIndex(dt.index.date).isin(exam_17)] = 1\n",
    "    \n",
    "    ## 2nd semester\n",
    "    exam_17_2 = pd.date_range(start='2017-06-12', end='2017-07-08')\n",
    "    dt['s_epochs'][pd.DatetimeIndex(dt.index.date).isin(exam_17_2)] = 1\n",
    "\n",
    "\n",
    "    #### 2018\n",
    "    ### CLASS PERIOD\n",
    "    ## 2nd Semester\n",
    "    class_18_2 = pd.date_range(start='2018-02-19', end='2018-06-01')\n",
    "    dt['s_epochs'][pd.DatetimeIndex(dt.index.date).isin(class_18_2)] = 2\n",
    "    \n",
    "    # Breaks in 2nd semester\n",
    "    # Easter Break\n",
    "    easter_18 = pd.date_range(start='2018-04-26', end='2018-04-30')\n",
    "    dt['s_epochs'][pd.DatetimeIndex(dt.index.date).isin(easter_18)] = 0\n",
    "    \n",
    "    \n",
    "    ## 1st Semester\n",
    "    class_18 = pd.date_range(start='2018-09-17', end='2018-12-21')\n",
    "    dt['s_epochs'][pd.DatetimeIndex(dt.index.date).isin(class_18)] = 2\n",
    "\n",
    "    ## EXAMS PERIOD\n",
    "    # represent all the period, with first and second wave of exams\n",
    "    ## 1st semester\n",
    "    exam_18 = pd.date_range(start='2018-01-06', end='2018-02-03')\n",
    "    dt['s_epochs'][pd.DatetimeIndex(dt.index.date).isin(exam_18)] = 1\n",
    "    \n",
    "    ## 2nd semester\n",
    "    exam_18_2 = pd.date_range(start='2018-06-09', end='2018-07-07')\n",
    "    dt['s_epochs'][pd.DatetimeIndex(dt.index.date).isin(exam_18_2)] = 1\n",
    "    \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create s_epochs feature\n",
    "dt_01 = different_epochs(dt_01)\n",
    "dt_02 = different_epochs(dt_02)\n",
    "dt_03 = different_epochs(dt_03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Energy Consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This category was used to create a sort of **“guidelines”** using each building consumption, to enhance\n",
    "the performance of the forecasting models. These “guidelines” can be distinguished into two different\n",
    "groups, according to the technique used to generate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Average Cluster Consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first group uses the mean daily pattern consumption of each cluster identified in 2017 year (previous notebook **02-00-EDA-Energy_Consumption_Analysis**) to create a new feature. \n",
    "\n",
    "Basically, this feature replicates each cluster mean pattern along all the data frame, as it is illustrate in **Fig. 4**.\n",
    "\n",
    "There are as many new features per building as clusters identified:\n",
    "- [3](#civil_building) clusters/features for Civil Building\n",
    "- [4](#south_tower) clusters/features for South Tower\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://imgur.com/lM23B2W.png\" width=\"550\" height=\"400\" align=\"center\"/>\n",
    "<center> <b>Fig.4</b> - Civil Building cluster average feature from k=0 <center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-04bae95ae34b>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-04bae95ae34b>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    X_building = building_pivot..copy()\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def create_mean_cluster_feat(dt, building_name):\n",
    "    \n",
    "    # dt_02 will be used for the clusters, since its the one that the consumption of each building was not dropped nor imputed\n",
    "    # Year = 2017 - since it is the closest year to the prediction year\n",
    "    building = pd.read_csv('Preprocessed_Data/_01_dt_02.csv', index_col=[0], parse_dates=[0], header=0)['2017']\n",
    "    building = building[[building_name]+['t_hour']]\n",
    "    \n",
    "    # Pivot column 't_hour' & drop incompleted days\n",
    "    building_pivot = building.pivot(columns='t_hour').dropna()\n",
    "    \n",
    "    # Create a copy of a dataframe\n",
    "    X_building = building_pivot.values.copy()\n",
    "    \n",
    "    # Scale for K-Means\n",
    "    scaler = MinMaxScaler()\n",
    "    X_building = scaler.fit_transform(X_building)\n",
    "    \n",
    "    # Predefined Silhouette Scores by building\n",
    "    if building_name == 'civil':\n",
    "        n_clusters = 3\n",
    "        \n",
    "    # Representing South tower\n",
    "    else:\n",
    "        n_clusters = 4\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    \n",
    "    cluster_found = kmeans.fit_predict(X_building)\n",
    "    \n",
    "    # Convert each day to series\n",
    "    cluster_found_sr = pd.Series(cluster_found, name='cluster')\n",
    "    \n",
    "    # Append cluster data\n",
    "    clustered_building_pivot = building_pivot.set_index(cluster_found_sr, append=True)\n",
    "\n",
    "    # Create a column for each n_clusters of the mean hourly data\n",
    "    for i in range(n_clusters):\n",
    "        mapping = dict(clustered_building_pivot.xs(i, level=1).mean().reset_index(level=0)[0])\n",
    "        dt['cl_'+building_name+'_'+str(i)] = dt.index.hour.map(mapping)\n",
    "        \n",
    "    return dt\n",
    "\n",
    "\n",
    "def cluster_pattern(dt):\n",
    "    buildings = ['civil', 'south_tower']\n",
    "    for name in buildings:\n",
    "        dt = create_mean_cluster_feat(dt, name)\n",
    "    return dt      \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 24)) while a minimum of 1 is required by MinMaxScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2fbd05c7cb61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdt_01\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt_01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdt_02\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt_02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdt_03\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt_03\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-c93ab3d05927>\u001b[0m in \u001b[0;36mcluster_pattern\u001b[0;34m(dt)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mbuildings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'civil'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'south_tower'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbuildings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_mean_cluster_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-c93ab3d05927>\u001b[0m in \u001b[0;36mcreate_mean_cluster_feat\u001b[0;34m(dt, building_name)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Scale for K-Means\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mX_building\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_building\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Predefined Silhouette Scores by building\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/thesis/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/thesis/lib/python3.6/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/thesis/lib/python3.6/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    369\u001b[0m         X = self._validate_data(X, reset=first_pass,\n\u001b[1;32m    370\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                                 force_all_finite=\"allow-nan\")\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/thesis/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 )\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/thesis/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/thesis/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    652\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[0;32m--> 654\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 24)) while a minimum of 1 is required by MinMaxScaler."
     ]
    }
   ],
   "source": [
    "dt_01 = cluster_pattern(dt_01)\n",
    "dt_02 = cluster_pattern(dt_02) \n",
    "dt_03 = cluster_pattern(dt_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
